# 10. 확장성 및 성능

[← 메인 문서로 돌아가기](../01_ams_system_architecture.md)

---

AMS는 초기 단일 인스턴스 운영에서 출발하되, 멀티 테넌트 서비스 특성을 고려하여 수평·수직 확장과 캐싱, 성능 모니터링 체계를 단계적으로 강화합니다. 본 절에서는 [2.1 고수준 아키텍처](02_architecture_diagrams.md#21-고수준-아키텍처-다이어그램-시스템-전체-구성도), [7. 비동기 처리 전략](07_async_processing.md), [11. 모니터링 및 로깅](11_monitoring_logging.md), [12. 배포 및 운영](12_deployment_operations.md)과 연계되는 확장/성능 전략을 기술합니다.

### 10.1 수평 확장 전략 (멀티 서버 & 멀티 인스턴스)

- **애플리케이션 계층**: 모든 인스턴스는 Stateless로 설계하고(세션은 Redis/DB에 저장), 로드 밸런서를 통해 트래픽을 균등 분배합니다. 오토스케일 조건은 CPU 60% 이상 5분 지속, 또는 초당 요청 수(QPS) 80% 초과 시 신규 인스턴스 추가를 기본값으로 설정합니다.
- **CQRS 데이터 계층**:
  - **PostgreSQL**: 읽기 부하 분산을 위해 Read Replica를 운영하고, 데이터 증가 속도를 모니터링하여 파티셔닝 혹은 샤딩 도입 여부를 검토합니다.
  - **MongoDB**: 조회 부하 증가 시 컬렉션별 샤딩을 적용하고, 샤드 키는 조회 패턴에 기반한 필드를 선택합니다.
- **비동기 컴포넌트**: 이벤트 핸들러, 알림 어댑터 등의 아웃바운드 작업은 메시지 큐 기반 병렬 소비를 고려합니다. 초기에는 애플리케이션 내부 큐(Coroutine Channel)를 사용하되, 트래픽 급증 시 Kafka/RabbitMQ 도입을 통해 소비자 인스턴스를 독립 확장합니다.
- **다중 AZ/리전 전략**: 운영 단계에서 고가용성이 요구될 경우, 다중 가용 영역에 인스턴스를 배치하고 데이터베이스 레플리케이션을 동기/비동기 모드로 조정합니다. 장애 조치 절차는 [12. 배포 및 운영](12_deployment_operations.md)에 정의된 재해 복구(드릴) 시나리오와 통합합니다.

| 계층         | 확장 방법                          | 모니터링 지표           | 후속 검토 포인트             |
|------------|--------------------------------|-------------------|-----------------------|
| 애플리케이션     | Kubernetes HPA / AWS ASG 오토스케일 | CPU, QPS, 평균 응답시간 | Warm-up 시간, 인스턴스 수 한도 |
| PostgreSQL | Read Replica, 향후 파티셔닝          | TPS, 복제 지연, 커넥션 수 | 파티션 키 설계, Vacuum 부하   |
| MongoDB    | 샤딩, 컬렉션별 인덱스 조정                | 서브샘플 응답시간, 커넥션    | 샤드 키 선정, Balancer 스케줄 |
| 이벤트/알림     | 소비자 인스턴스 증가, MQ 도입             | 큐 적체량, 실패율        | 메시지 중복 처리, DLQ 정책     |

### 10.2 수직 확장 전략

- **애플리케이션 자원 상향**: 초기 단계에서는 vCPU/메모리 스펙을 조정하여 급격한 트래픽 증가에 대응합니다. JVM 힙 크기, Coroutine Dispatcher 스레드 수를 조정하고, JDK 21 이상 환경에서는 G1GC 또는 ZGC 기반으로 GC 파라미터를 튜닝하여 적정한 처리량을 확보합니다.
- **데이터베이스 업사이징**: PostgreSQL은 IOPS/메모리 기반 인스턴스 클래스로 상향, MongoDB는 WiredTiger 캐시 비율 조정 및 노드 스펙 업그레이드를 고려합니다. 업그레이드 전후에는 워크로드 재측정과 쿼리 플랜 분석을 수행합니다.
- **네트워크/스토리지 최적화**: 네트워크 대역폭 확대, EBS/스토리지 Throughput 향상 옵션을 검토합니다. 성능 병목 지점은 [11. 모니터링 및 로깅](11_monitoring_logging.md)에서 수집하는 APM 지표를 통해 주기적으로 확인합니다.
- **전환 기준**: 수직 확장의 한계(예: CPU 80% 이상 지속, Replica 동기화 지연) 도달 시 9.1에서 정의한 수평 확장 또는 마이크로서비스 분리를 검토합니다.

### 10.3 로드 밸런싱 전략

- **L4/L7 분리 운용**: L4 로드 밸런서에서 기본 트래픽 분산을 담당하고, L7 계층(추후 API Gateway 포함)에서 인증 헤더 검증, 멀티 테넌트 라우팅, 요청 사이즈 제한을 수행합니다.
- **분산 알고리즘**: 기본은 라운드 로빈을 적용하되, 인스턴스 성능이 이질적일 경우 가중 라운드 로빈으로 전환합니다. 세션 스티키니스는 사용하지 않으며, 세션 데이터는 외부 저장소(9.4 캐싱 전략)로 이관합니다.
- **헬스체크 및 장애 처치**: `/actuator/health` 기반 헬스체크를 10초 주기로 수행하고, 3회 연속 실패 시 인스턴스를 분리합니다. Circuit Breaker(12장)와 연계하여 비정상 구간의 요청 차단 및 재시도를 관리합니다.
- **배포 전략과 연계**: 블루-그린 및 카나리 배포(11장) 시 로드 밸런서 가중치를 조정하여 신규 릴리스로 트래픽을 점진 전환합니다. 트래픽 스플릿 결과는 모니터링 대시보드에서 실시간으로 관찰합니다.

### 10.4 캐싱 전략 (Redis 등)

- **1단계: 애플리케이션 캐시**: 자주 사용되는 설정/레퍼런스 데이터는 애플리케이션 내부 캐시(예: Caffeine)로 보관하되 TTL을 5분 이내로 제한하여 데이터 최신성을 확보합니다.
- **2단계: Redis 기반 공용 캐시**:
  - **구조**: Redis Cluster를 도입하여 세션, 토큰, 조회 결과 캐시를 저장합니다. 멱등 키 저장소와 비동기 이벤트 de-duplication도 Redis를 활용합니다.
  - **정책**: TTL은 데이터 특성에 따라 분류(`short-lived` 30초, `medium` 5분, `long` 1시간). 캐시 무효화는 이벤트 기반(도메인 이벤트 → 캐시 무효화 메시지)으로 처리합니다.
- **CQRS 연계**: MongoDB 조회 모델은 읽기 성능이 충분한 경우 캐시 없이 운영하되, 대량 조회/통계 API는 Redis read-through 캐시를 적용해 응답 시간을 단축합니다.
- **모니터링 및 장애 대응**: 캐시 적중률, 메모리 사용률, 복제 지연을 모니터링하고, Redis 장애 시 폴백(직접 DB 조회) 로직을 구현합니다. 폴백 시 발생할 부하를 대비해 DB 읽기 한도와 Circuit Breaker를 조정합니다.

### 10.5 성능 최적화 방안

- **성능 목표**:
  - SLA: 월 가용성 99.5% 이상.
  - SLO: 주요 API p95 응답시간 300ms 이하, 오류율 0.5% 이하.
  - 이를 달성하기 위해 APM(New Relic, Datadog 등)과 로그/메트릭 수집(10장)을 결합합니다.
- **코드/아키텍처 최적화**:
  - Coroutine 기반 Non-Blocking I/O를 적극 활용하여 Thread Blocking을 최소화합니다(6장 참조).
  - CQRS로 읽기/쓰기 부하를 분리하고, Command 처리 후 이벤트 기반으로 비즈니스 연산을 분산합니다.
  - 배치/집계 작업은 별도 워커 또는 스케줄러로 분리하여 온라인 트래픽과 분리합니다.
- **테스트 및 검증**:
  - 부하 테스트: JMeter/K6 등을 활용하여 피크 트래픽(평균 대비 3배) 시나리오를 재현하고, 오토스케일 반응 시간을 측정합니다.
  - 회귀 검증: CI/CD 파이프라인에서 성능 테스트 Smoke Suite를 실행하고, 기준치 초과 시 배포를 차단합니다.
  - 프로파일링: CPU/메모리 분석(Async Profiler, Java Flight Recorder) 결과를 주기적으로 검토하여 Hot Spot을 제거합니다.
- **운영 프로세스**: 용량 계획 회의(월 1회)에서 성장률, 비용, 장애 사례를 공유하고, SLO 위반 시 사후 분석(Postmortem)을 작성하여 개선 과제를 추적합니다.

---

## 다음 문서

[→ 11. 모니터링 및 로깅](11_monitoring_logging.md)

